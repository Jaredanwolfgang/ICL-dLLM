model:
    family: diffusion_encoder
    n_embd: 256
    n_layer: 12
    n_head: 8
    n_dims: 20
    n_positions: 101

training:
    task: "relu_2nn_regression"
    data: gaussian
    task_kwargs: {"hidden_layer_size": 100}
    batch_size: 64
    learning_rate: 1e-5
    save_every_steps: 1000
    keep_every_steps: 100000
    train_steps: 500001
    curriculum:
        dims:
            end: 20
            inc: 1
            interval: 100
            start: 5
        points:
            start: 26
            end: 101
            inc: 5
            interval: 2000

out_dir: "../models/relu2nn_encoder"

wandb:
    enabled: true
    project: icl-dllm
    entity: jaredanjerry-southern-university-of-science-technology
    notes: "Training"
    name: "relu2nn_encoder"
    log_every_steps: 10