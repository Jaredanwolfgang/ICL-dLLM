import torch
import torch.nn as nn
import torch.nn.functional as F
import math
import tqdm  # å»ºè®®å®‰è£… tqdm: pip install tqdm

import torch
import torch.nn as nn
import torch.nn.functional as F
import math

# ==========================================
# 1. è¾…åŠ©å·¥å…· (Schedule & Embedding)
# ==========================================
class DiffusionSchedule:
    def __init__(self, timesteps=100, beta_start=1e-4, beta_end=0.02, device="cpu"):
        self.timesteps = timesteps
        self.betas = torch.linspace(beta_start, beta_end, timesteps, device=device)
        self.alphas = 1.0 - self.betas
        self.alphas_cumprod = torch.cumprod(self.alphas, dim=0)
        
        # è®¡ç®—è¾…åŠ©å˜é‡ (ä¸ºäº†ä»£ç æ¸…æ™°ï¼Œæå‰ç®—å¥½)
        self.sqrt_alphas_cumprod = torch.sqrt(self.alphas_cumprod)
        self.sqrt_one_minus_alphas_cumprod = torch.sqrt(1.0 - self.alphas_cumprod)
        self.sqrt_recip_alphas = torch.sqrt(1.0 / self.alphas)

def extract(a, t, x_shape):
    """
    ä»å¼ é‡ a ä¸­æå– t ç´¢å¼•çš„å€¼ï¼Œå¹¶ reshape åˆ° x_shape ä»¥ä¾¿å¹¿æ’­
    a: (T,)
    t: (B,)
    x_shape: (B, P, D, ...)
    """
    b, *_ = t.shape
    out = a.gather(-1, t)
    return out.reshape(b, *((1,) * (len(x_shape) - 1)))

# ==========================================
# 2. æ¸…æ™°ç‰ˆ Linear Regression Diffusion
# ==========================================
class LinearRegressionDiffusion(nn.Module):
    def __init__(self, n_x_dims, n_embd=256, n_layer=6, n_head=8, timesteps=100):
        super().__init__()
        self.n_x_dims = n_x_dims
        self.n_y_dims = 1
        self.n_embd = n_embd
        self.timesteps = timesteps

        # 1. æŠ•å½±å±‚: [x, y] -> embedding
        self.input_proj = nn.Linear(n_x_dims + 1, n_embd)
        
        # 2. æ—¶é—´åµŒå…¥
        self.time_embed = nn.Sequential(
            nn.Linear(1, n_embd),
            nn.SiLU(),
            nn.Linear(n_embd, n_embd),
        )

        # 3. ä¸»å¹²: Full Attention Transformer (Encoder)
        # encoder_layer = nn.TransformerEncoderLayer(
        #     d_model=n_embd, 
        #     nhead=n_head, 
        #     dim_feedforward=n_embd * 4, 
        #     dropout=0.0, 
        #     activation="gelu", 
        #     batch_first=True, 
        #     norm_first=True
        # )
        # self.backbone = nn.TransformerEncoder(encoder_layer, num_layers=n_layer)
        # GPT2 Config
        config = GPT2Config(
            n_positions=2 * n_positions,  # åºåˆ—æ€»é•¿åº¦ä¾ç„¶æ˜¯ 2P
            n_embd=n_embd,
            n_layer=n_layer,
            n_head=n_head,
            resid_pdrop=0.0,
            embd_pdrop=0.0,
            attn_pdrop=0.0,
            use_cache=False,
        )
        self.backbone = GPT2Model(config)

        # 4. è¾“å‡ºå±‚: é¢„æµ‹å™ªå£°
        self.eps_head = nn.Linear(n_embd, 1)
        
        self.schedule = None

    def _get_schedule(self, device):
        if self.schedule is None or self.schedule.betas.device != device:
            self.schedule = DiffusionSchedule(self.timesteps, device=device)
        return self.schedule

    # ============================================
    # æ ¸å¿ƒè¿‡ç¨‹ 1: å‰å‘ä¼ æ’­ (Model Prediction)
    # ============================================
    def forward(self, xs, ys_current, t):
        """
        xs:         (B, P, Dx) æ¡ä»¶
        ys_current: (B, P, 1)  å½“å‰çš„ y (åŒ…å« Context éƒ¨åˆ†çš„ Clean å’Œ Target éƒ¨åˆ†çš„ Noisy)
        t:          (B,)       æ—¶é—´æ­¥
        """
        # 1. Input Projection
        # æ‹¼æ¥ x å’Œ yï¼Œå½¢æˆ Transformer çš„è¾“å…¥ Token
        inp = torch.cat([xs, ys_current], dim=-1) # (B, P, D+1)
        emb = self.input_proj(inp)

        # 2. Add Time Embedding
        # å°†æ—¶é—´ t å½’ä¸€åŒ–åæ˜ å°„ï¼Œå¹¶åŠ åˆ°æ‰€æœ‰ Token ä¸Š
        t_vec = t.float().unsqueeze(-1) / self.timesteps
        t_emb = self.time_embed(t_vec)            # (B, n_embd)
        emb = emb + t_emb[:, None, :]

        # 3. Backbone (Global Attention)
        # æ­¤æ—¶æ‰€æœ‰ä½ç½® (Context å’Œ Target) éƒ½èƒ½äº’ç›¸çœ‹åˆ°
        out = self.backbone(emb)

        # 4. Predict Noise
        return self.eps_head(out)

    # ============================================
    # æ ¸å¿ƒè¿‡ç¨‹ 2: åŠ å™ªè¿‡ç¨‹ (Diffusion Forward)
    # ============================================
    def q_sample(self, y0, t, noise=None):
        """
        æ ‡å‡†åŠ å™ªå…¬å¼: y_t = sqrt(alpha_bar) * y0 + sqrt(1-alpha_bar) * eps
        """
        if noise is None:
            noise = torch.randn_like(y0)
            
        schedule = self._get_schedule(y0.device)
        
        sqrt_alphas_cumprod_t = extract(schedule.sqrt_alphas_cumprod, t, y0.shape)
        sqrt_one_minus_alphas_cumprod_t = extract(schedule.sqrt_one_minus_alphas_cumprod, t, y0.shape)
        
        y_t = sqrt_alphas_cumprod_t * y0 + sqrt_one_minus_alphas_cumprod_t * noise
        return y_t, noise

    # ============================================
    # æ ¸å¿ƒè¿‡ç¨‹ 3: è®­ç»ƒ Loss (Hybrid Strategy)
    # ============================================
    def compute_loss(self, xs, ys_gt):
        """
        æ··åˆè®­ç»ƒç­–ç•¥:
        1. éšæœºåˆ‡åˆ†åºåˆ—ä¸º Context (Clean) å’Œ Target (Noisy)ã€‚
        2. Context å¸®åŠ©æ¨¡å‹ç†è§£ x->y çš„å…³ç³»ã€‚
        3. Target æä¾›åŠ å™ªæ ·æœ¬ä¾›æ¨¡å‹å»å™ªã€‚
        """
        B, P, _ = ys_gt.shape
        device = ys_gt.device
        schedule = self._get_schedule(device)

        # 1. éšæœºé‡‡æ ·æ—¶é—´æ­¥ t
        t = torch.randint(0, schedule.timesteps, (B,), device=device)

        # 2. ç”Ÿæˆ Context/Target æ©ç 
        # ä¸ºæ¯ä¸ªæ ·æœ¬éšæœºé€‰ä¸€ä¸ªåˆ‡åˆ†ç‚¹ k (k in [1, P-1])
        ks = torch.randint(1, P, (B,), device=device)
        indices = torch.arange(P, device=device).unsqueeze(0).expand(B, P)
        
        # mask_target: True è¡¨ç¤ºè¯¥ä½ç½®æ˜¯ Target (éœ€è¦åŠ å™ª)ï¼ŒFalse è¡¨ç¤º Context (ä¿æŒå¹²å‡€)
        mask_target = (indices >= ks.unsqueeze(1)).unsqueeze(-1).float() # (B, P, 1)

        # 3. æ„é€ è¾“å…¥ y_t (Hybrid)
        # å¯¹æ•´ä¸ªåºåˆ—è®¡ç®—åŠ å™ªç‰ˆæœ¬
        y_noisy_full, noise_true = self.q_sample(ys_gt, t)
        
        # æ··åˆ: å¦‚æœæ˜¯ Target ç”¨ Noisyï¼Œå¦‚æœæ˜¯ Context ç”¨ Clean (GT)
        # y_input = mask * y_noisy + (1-mask) * y_clean
        ys_input = mask_target * y_noisy_full + (1.0 - mask_target) * ys_gt

        # 4. æ¨¡å‹é¢„æµ‹
        # æ³¨æ„ï¼šè¿™é‡Œä¼ å…¥çš„ t å¯¹åº”çš„æ˜¯ Target çš„å™ªå£°ç¨‹åº¦ã€‚Context è™½ç„¶æ˜¯ Clean (t=0)ï¼Œ
        # ä½†æˆ‘ä»¬ç»Ÿä¸€ä¼  tã€‚æ¨¡å‹å› ä¸ºèƒ½çœ‹åˆ° Context æ˜¯ Clean çš„ï¼Œä¼šè‡ªåŠ¨å­¦ä¼šåˆ©ç”¨å®ƒã€‚
        eps_pred = self.forward(xs, ys_input, t)

        # 5. è®¡ç®— Loss
        # åªåœ¨ Target éƒ¨åˆ†è®¡ç®— MSE
        loss = F.mse_loss(eps_pred, noise_true, reduction='none')
        loss = (loss * mask_target).sum() / mask_target.sum().clamp(min=1)

        return loss

    # ============================================
    # æ ¸å¿ƒè¿‡ç¨‹ 4: å•æ­¥å»å™ª (Inverse Step)
    # ============================================
    @torch.no_grad()
    def p_sample(self, xs, y_t, t, t_index):
        """
        æ ‡å‡† DDPM é‡‡æ ·æ­¥: y_{t-1} = 1/sqrt(alpha) * (y_t - ...) + sigma * z
        """
        schedule = self._get_schedule(xs.device)
        
        # 1. é¢„æµ‹å™ªå£°
        eps_pred = self.forward(xs, y_t, t)
        
        # 2. æå–ç³»æ•°
        betas_t = extract(schedule.betas, t, y_t.shape)
        sqrt_one_minus_alphas_cumprod_t = extract(schedule.sqrt_one_minus_alphas_cumprod, t, y_t.shape)
        sqrt_recip_alphas_t = extract(schedule.sqrt_recip_alphas, t, y_t.shape)
        
        # 3. è®¡ç®—å‡å€¼ mu
        # mu = (1 / sqrt(alpha_t)) * (y_t - (beta_t / sqrt(1 - alpha_bar_t)) * eps)
        model_mean = sqrt_recip_alphas_t * (
            y_t - (betas_t / sqrt_one_minus_alphas_cumprod_t) * eps_pred
        )

        # 4. è®¡ç®—æ–¹å·® (t > 0 æ—¶åŠ å™ªå£°)
        if t_index > 0:
            noise = torch.randn_like(y_t)
            # ä½¿ç”¨ç®€å•çš„æ–¹å·® sigma = sqrt(beta)
            posterior_variance_t = extract(torch.sqrt(schedule.betas), t, y_t.shape)
            y_prev = model_mean + posterior_variance_t * noise
        else:
            y_prev = model_mean
            
        return y_prev

    # ============================================
    # æ ¸å¿ƒè¿‡ç¨‹ 5: å®Œæ•´é‡‡æ ·å¾ªç¯ (Inference Loop)
    # ============================================
    @torch.no_grad()
    def p_sample_loop(self, xs, ys_demo, n_query):
        """
        ICL æ¨ç†å¾ªç¯:
        xs: å…¨é‡ x
        ys_demo: å·²çŸ¥çš„ y (Clean)
        n_query: éœ€è¦é¢„æµ‹çš„ç‚¹æ•°
        """
        device = xs.device
        B, P, _ = xs.shape
        schedule = self._get_schedule(device)
        n_demo = P - n_query

        # 1. åˆå§‹åŒ–: Context æ˜¯ Clean çš„ï¼ŒQuery æ˜¯çº¯å™ªå£°
        y_query_noisy = torch.randn(B, n_query, 1, device=device)
        ys_current = torch.cat([ys_demo, y_query_noisy], dim=1) # (B, P, 1)
        
        # 2. è¿­ä»£å»å™ª
        for i in reversed(range(schedule.timesteps)):
            t = torch.full((B,), i, device=device, dtype=torch.long)
            
            # æ‰§è¡Œä¸€æ­¥å»å™ª (Update Whole Sequence)
            # è™½ç„¶æˆ‘ä»¬åªå…³å¿ƒ Queryï¼Œä½†ä¸ºäº†åˆ©ç”¨ Transformer çš„å…¨å±€ Attentionï¼Œ
            # æˆ‘ä»¬é€šå¸¸æŠŠæ•´ä¸ªåºåˆ—æ‰”è¿›å»é¢„æµ‹ã€‚
            y_prev_full = self.p_sample(xs, ys_current, t, i)
            
            # 3. å¼ºåˆ¶ In-painting (Context Replacement)
            # å…³é”®æ­¥éª¤ï¼šæ— è®ºæ¨¡å‹å¯¹ Demo éƒ¨åˆ†é¢„æµ‹å˜æˆä»€ä¹ˆæ ·ï¼Œ
            # åœ¨æ¯ä¸€æ­¥ç»“æŸåï¼Œå¼ºåˆ¶æŠŠ Demo éƒ¨åˆ†é‡ç½®å› Ground Truthã€‚
            # è¿™æ ·æ¨¡å‹åœ¨ä¸‹ä¸€æ­¥é¢„æµ‹ Query æ—¶ï¼Œæ€»èƒ½çœ‹åˆ°å®Œç¾çš„ Contextã€‚
            
            # æå– Query çš„æ›´æ–°ç»“æœ
            y_query_updated = y_prev_full[:, n_demo:, :]
            
            # é‡æ–°æ‹¼æ¥: Demo (Clean) + Query (Updated)
            ys_current = torch.cat([ys_demo, y_query_updated], dim=1)
            
        return ys_current

# ==========================================
# 3. å¤§è§„æ¨¡è®­ç»ƒæµç¨‹
# ==========================================
def train_large_scale():
    DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
    
    # --- é…ç½®: æ‰©å¤§è§„æ¨¡ ---
    D = 20          # ç»´åº¦ (Scale Up!)
    P = 64          # åºåˆ—é•¿åº¦ (Scale Up!)
    BATCH_SIZE = 64
    STEPS = 10000   # æ›´å¤šæ­¥æ•°
    LR = 3e-4
    
    # åˆå§‹åŒ–æ¨¡å‹
    model = LinearRegressionDiffusion(
        n_x_dims=D, 
        n_embd=256,   # å®¹é‡å¢åŠ 
        n_layer=6,    # æ·±åº¦å¢åŠ 
        n_head=8,     # å¤´æ•°å¢åŠ 
        timesteps=100
    ).to(DEVICE)
    
    optimizer = torch.optim.AdamW(model.parameters(), lr=LR, weight_decay=1e-4)
    # Cosine Annealing å­¦ä¹ ç‡è°ƒåº¦å™¨
    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=STEPS)
    
    print(f"--- Starting Large Scale Training (D={D}, P={P}) ---")
    model.train()
    
    pbar = tqdm.tqdm(range(STEPS))
    for step in pbar:
        optimizer.zero_grad()
        
        # 1. ç”Ÿæˆé«˜ç»´æ•°æ®
        xs = torch.randn(BATCH_SIZE, P, D, device=DEVICE)
        
        # ã€å…³é”®ã€‘å¯¹ Weights è¿›è¡Œç¼©æ”¾ï¼Œä¿æŒ y çš„æ–¹å·® ~ 1.0
        ws = torch.randn(BATCH_SIZE, D, 1, device=DEVICE) / math.sqrt(D)
        
        ys = torch.bmm(xs, ws) # (B, P, 1)
        
        # 2. Hybrid Loss
        loss = model.compute_hybrid_loss(xs, ys)
        
        loss.backward()
        
        # æ¢¯åº¦è£å‰ª
        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)
        
        optimizer.step()
        scheduler.step()
        
        if step % 100 == 0:
            pbar.set_description(f"Loss: {loss.item():.4f} | LR: {scheduler.get_last_lr()[0]:.2e}")
            
    # ================= EVALUATION =================
    print("\n--- Evaluation on Test Set ---")
    model.eval()
    
    # ç”Ÿæˆæµ‹è¯•é›† (æ›´å¤§ Batch ä»¥æ±‚ç¨³)
    TEST_BATCH = 100
    test_xs = torch.randn(TEST_BATCH, P, D, device=DEVICE)
    test_ws = torch.randn(TEST_BATCH, D, 1, device=DEVICE) / math.sqrt(D)
    test_ys = torch.bmm(test_xs, test_ws)
    
    # è®¾å®š Query æ•°é‡
    n_query = 5 # é¢„æµ‹æœ€å5ä¸ªç‚¹
    ys_demo = test_ys[:, :-n_query, :]
    ys_truth = test_ys[:, -n_query:, :]
    
    # é‡‡æ ·
    ys_pred_full = model.sample_icl(test_xs, ys_demo, n_query)
    ys_pred_query = ys_pred_full[:, -n_query:, :]
    
    # è®¡ç®—æŒ‡æ ‡
    mse = F.mse_loss(ys_pred_query, ys_truth).item()
    var_ref = ys_truth.var().item()
    r2_score = 1.0 - (mse / var_ref)
    
    print(f"Baseline Variance: {var_ref:.4f}")
    print(f"Model MSE:         {mse:.4f}")
    print(f"RÂ² Score:          {r2_score:.4f} (Closer to 1.0 is better)")
    
    if r2_score > 0.9:
        print("ğŸš€ Excellent! High-dimensional ICL achieved.")
    elif r2_score > 0.5:
        print("âœ… Good. Model is learning, but maybe needs more steps.")
    else:
        print("âš ï¸ Failed to generalize to high dimensions.")

    # Visual Check (First sample)
    print("\nSample 0 Visualization (Last 5 points):")
    # åªæ‰“å°å‰3ä¸ªç»´åº¦å¦‚æœæ˜¯å¤šç»´yï¼Œè¿™é‡Œyæ˜¯1ç»´
    print("Truth:", ys_truth[0].flatten().detach().cpu().numpy().round(3))
    print("Pred :", ys_pred_query[0].flatten().detach().cpu().numpy().round(3))

if __name__ == "__main__":
    train_large_scale()