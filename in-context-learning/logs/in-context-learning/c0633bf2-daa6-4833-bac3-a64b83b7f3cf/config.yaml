model:
  family: gpt2
  n_dims: 20
  n_embd: 128
  n_head: 4
  n_layer: 2
  n_positions: 101
out_dir: logs/in-context-learning/c0633bf2-daa6-4833-bac3-a64b83b7f3cf
test_run: false
training:
  batch_size: 64
  curriculum:
    dims:
      end: 20
      inc: 1
      interval: 2000
      start: 5
    points:
      end: 20
      inc: 1
      interval: 2000
      start: 5
  data: gaussian
  keep_every_steps: 100000
  learning_rate: 0.0001
  num_tasks: null
  num_training_examples: null
  resume_id: null
  save_every_steps: 1000
  task: linear_regression
  task_kwargs: {}
  train_steps: 500001
wandb:
  entity: jaredanjerry
  log_every_steps: 10
  name: base
  notes: Base configuration
  project: in-context-learning
